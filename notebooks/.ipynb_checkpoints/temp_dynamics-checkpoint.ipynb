{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cvxpy as cp\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from scipy.integrate import solve_ivp\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import signal\n",
    "from scipy.interpolate import interp1d\n",
    "import scipy as sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" hyperparameters \"\"\"\n",
    "# ambient temp\n",
    "Tamb = 25.\n",
    "\n",
    "# model dimension\n",
    "n = 4\n",
    "\n",
    "# discretization interval\n",
    "tau = 0.2\n",
    "\n",
    "# data scaling factor\n",
    "scale = 1.0\n",
    "\n",
    "# regularization\n",
    "l1_reg = 1e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resample(s: pd.Series) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Resample a pandas Series with unevenly spaced time indices to be even.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    s : pd.Series\n",
    "        The input signal as a pandas Series. The Series index should be time.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    tuple\n",
    "        The resampled signal as a pandas Series, resampling period as a float,\n",
    "        and new timebase as a numpy array.\n",
    "    \"\"\"\n",
    "    assert isinstance(s, pd.Series)\n",
    "    \n",
    "    # Resampling parameters - change these to suit your data\n",
    "    resampling_period = s.index.to_series().diff().mean()\n",
    "    \n",
    "    # Interpolate to a new time base (resample)\n",
    "    f_interp = interp1d(s.index, s.values, kind='linear',\n",
    "                        fill_value='extrapolate')\n",
    "    new_timebase = np.arange(s.index.min(), s.index.max(), resampling_period)\n",
    "    if new_timebase[-1] < s.index.max():\n",
    "        new_timebase = np.append(new_timebase, s.index.max())\n",
    "    s_interpolated = pd.Series(f_interp(new_timebase), index=new_timebase)\n",
    "    \n",
    "    return s_interpolated, resampling_period, new_timebase\n",
    "\n",
    "\n",
    "def lowpass_filter_series(s: pd.Series, cutoff_freq: float, \n",
    "                          butterworth_order: int) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Apply a lowpass Butterworth filter to a pandas Series with uneven time\n",
    "    indices.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    s : pd.Series\n",
    "        The input signal as a pandas Series. The Series index should be time.\n",
    "    cutoff_freq : float\n",
    "        The cutoff frequency for the lowpass filter.\n",
    "    butterworth_order : int\n",
    "        The order of the Butterworth filter.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.Series\n",
    "        The filtered signal as a pandas Series.\n",
    "    \"\"\"\n",
    "    s_interpolated, resampling_period, new_timebase = resample(s)\n",
    "\n",
    "    # Create the low-pass filter\n",
    "    nyquist_rate = 0.5 / resampling_period\n",
    "    normalized_cutoff_freq = cutoff_freq / nyquist_rate\n",
    "    b, a = signal.butter(butterworth_order, normalized_cutoff_freq, \n",
    "                         btype='low')\n",
    "    \n",
    "    # Apply the low-pass filter\n",
    "    filtered_signal = signal.filtfilt(b, a, s_interpolated)\n",
    "    s_filtered_interpolated = pd.Series(filtered_signal, \n",
    "                                        index=new_timebase)\n",
    "\n",
    "    # Interpolate back to the original timebase\n",
    "    f_interp_back = interp1d(s_filtered_interpolated.index, \n",
    "                             s_filtered_interpolated.values, kind='linear')\n",
    "    s_filtered = pd.Series(f_interp_back(s.index), index=s.index)\n",
    "\n",
    "    return s_filtered\n",
    "\n",
    "\n",
    "def z_transform_series(s: pd.Series, a: list, b: list) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Apply a Z-transform to a pandas Series with unevenly spaced time indices.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    s : pd.Series\n",
    "        The input signal as a pandas Series. The Series index should be time.\n",
    "    a : list\n",
    "        The denominator coefficient vector in a 1-D sequence (filter's recursive part).\n",
    "    b : list\n",
    "        The numerator coefficient vector in a 1-D sequence (filter's non-recursive part).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.Series\n",
    "        The transformed signal as a pandas Series.\n",
    "    \"\"\"\n",
    "    s_interpolated, _, new_timebase = resample(s)\n",
    "\n",
    "    # Apply the Z-transform\n",
    "    transformed_signal = signal.lfilter(b, a, s_interpolated)\n",
    "    s_transformed_interpolated = pd.Series(transformed_signal, \n",
    "                                           index=new_timebase)\n",
    "\n",
    "    # Interpolate back to the original timebase\n",
    "    f_interp_back = interp1d(s_transformed_interpolated.index, \n",
    "                             s_transformed_interpolated.values, kind='linear')\n",
    "    s_transformed = pd.Series(f_interp_back(s.index), index=s.index)\n",
    "\n",
    "    return s_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = {\n",
    "    'temperature': pd.DataFrame(index=np.arange(4600), dtype=float),\n",
    "    'seconds': pd.DataFrame(index=np.arange(4600), dtype=float),\n",
    "    'heat': pd.DataFrame(index=np.arange(4600), dtype=float)\n",
    "}\n",
    "\n",
    "for filename in os.listdir('../logs/'):\n",
    "    df_read = pd.read_csv(f'../logs/{filename}', header=None)[0].values\n",
    "    if len(df_read) > 4600:\n",
    "        continue\n",
    "    df_read = np.pad(\n",
    "        df_read, ((0, 4600-len(df_read)),), 'constant', constant_values=np.nan\n",
    "    )\n",
    "\n",
    "    keys = filename.split('.')[0].split('_')\n",
    "    datatype = keys[1]\n",
    "    timestamp = keys[-1]\n",
    "\n",
    "    if datatype not in dfs.keys():\n",
    "        continue\n",
    "    dfs[datatype][timestamp] = df_read\n",
    "\n",
    "dfs = {\n",
    "    key: df.set_index([pd.MultiIndex.from_product([[key], df.index])]) \n",
    "    for key, df in dfs.items()\n",
    "}\n",
    "\n",
    "combined = pd.concat(dfs.values(), axis=0)\n",
    "null_heats = [\n",
    "    colname for colname in combined.columns \n",
    "    if np.isnan(combined.loc['heat', colname].iloc[0])\n",
    "]\n",
    "combined.drop(columns=null_heats, inplace=True)\n",
    "null_heats = [\n",
    "    colname for colname in combined.columns \n",
    "    if int(np.round(6*np.max(combined[colname].loc['heat']))) == 6 \n",
    "    and (combined[colname].loc['seconds'] > 0).sum() < 600\n",
    "]\n",
    "combined.drop(columns=null_heats, inplace=True)\n",
    "combined.rename(\n",
    "    lambda x: int(np.round(6*np.max(combined[x].loc['heat']))), \n",
    "    axis=1,\n",
    "    inplace=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = [2, 4, 5, 6]\n",
    "\n",
    "turnon = {}\n",
    "for i in indices:\n",
    "    turnon[i] = np.argmax(combined.loc['heat'][i])\n",
    "\n",
    "startidx = {}\n",
    "for i in indices:\n",
    "    startidx[i] = np.argmin(combined.loc['temperature'][i].iloc[:turnon[i]+10])\n",
    "\n",
    "# hit10 = {}\n",
    "# for i in indices:\n",
    "#     temp_curve = combined.loc['temperature'][i]\n",
    "#     wherelarge = temp_curve[temp_curve > 10]\n",
    "#     if len(wherelarge) > 0:\n",
    "#         hit10[i] = np.argmax(temp_curve > 10)\n",
    "#     else:\n",
    "#         hit10[i] = -1\n",
    "\n",
    "turnoff = {}\n",
    "for i in indices:\n",
    "    turnoff[i] = np.argmin(combined.loc['heat'][i].iloc[turnon[i]:]) + turnon[i]\n",
    "\n",
    "endidx = {}\n",
    "for i in indices:\n",
    "    endidx[i] = np.argmax(np.isnan(combined.loc['heat'][i]))\n",
    "\n",
    "temps_series = {}\n",
    "for i in indices:\n",
    "    secs = combined.loc['seconds'][i].iloc[turnon[i]:endidx[i]].values\n",
    "    secs -= secs[0]\n",
    "    temps = combined.loc['temperature'][i].iloc[turnon[i]:endidx[i]].values\n",
    "    temps_series[i] = pd.Series(temps, index=secs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in indices:\n",
    "    # secs = combined.loc['seconds'][i].iloc[turnon[i]:turnoff[i]].values\n",
    "    secs = combined.loc['seconds'][i].values\n",
    "    secs -= secs[0]\n",
    "    plt.plot(\n",
    "        secs,\n",
    "        # combined.loc['temperature'][i].iloc[turnon[i]:turnoff[i]].values,\n",
    "        combined.loc['temperature'][i].values,\n",
    "        label=str(i)\n",
    "    )\n",
    "    start = combined.loc['seconds'][i].iloc[turnon[i]]\n",
    "    stop = combined.loc['seconds'][i].iloc[turnoff[i]]\n",
    "    plt.vlines(start, 30, 110, label=\"start\", color=\"blue\")\n",
    "    plt.vlines(stop, 30, 110, label=\"end\", color=\"red\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess data\n",
    "data = {}\n",
    "for i in indices:\n",
    "    # time\n",
    "    secs = combined.loc['seconds'][i].values\n",
    "    secs -= secs[0]\n",
    "    start = combined.loc['seconds'][i].iloc[turnon[i]]\n",
    "    stop = combined.loc['seconds'][i].iloc[turnoff[i]]\n",
    "\n",
    "    # control\n",
    "    heat_level = i / 6.0\n",
    "    u = np.array([heat_level if s >= start and s <= stop else 0.0 for s in secs])\n",
    "\n",
    "    # temp\n",
    "    T = combined.loc['temperature'][i].values\n",
    "\n",
    "    idx = np.isfinite(secs)\n",
    "    data[i] = {\n",
    "        \"t\": secs[idx],\n",
    "        \"u\": u[idx],\n",
    "        \"T\": T[idx]\n",
    "    }\n",
    "\n",
    "    print(i, len(secs[idx]))\n",
    "\n",
    "# # add constant ambient temp @ 30 C\n",
    "# data[0] = {\n",
    "#     \"t\": data[2][\"t\"],\n",
    "#     \"u\": 0. * data[2][\"t\"],\n",
    "#     \"T\": Tamb * np.ones(len(data[2][\"t\"])),\n",
    "# }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dynamics fitting - torchdiffeq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from torchdiffeq import odeint\n",
    "# from torchdiffeq import odeint_adjoint as odeint\n",
    "\n",
    "\n",
    "class LinearDynamics(nn.Module):\n",
    "    \"\"\" Linear dynamics: x' = Ax + Bu \"\"\"\n",
    "    def __init__(self, n, m=1, Tamb=30.0):\n",
    "        super().__init__()\n",
    "        self.n = n\n",
    "        self.m = m\n",
    "        self.Tamb = Tamb\n",
    "\n",
    "        self.A = nn.Parameter(torch.zeros(n, n))\n",
    "        self.B = nn.Parameter(torch.randn(n, 1))\n",
    "\n",
    "    def c(self):\n",
    "        return -self.Tamb * self.A.sum(axis=1)\n",
    "\n",
    "    def forward(self, t, x, u=None):\n",
    "        return F.linear(x, self.A, bias=self.c()) + F.linear(u, self.B)\n",
    "\n",
    "class LookupLinearInterpolator:\n",
    "    \"\"\"\n",
    "        Interpolator requires init_interpolation to be called\n",
    "        before querying\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        # input sequence to be interpolated\n",
    "        self.t_seq = None\n",
    "        self.u_seq = None\n",
    "        self.length = 0\n",
    "\n",
    "    def init_interpolation(self, t_seq, u_seq):\n",
    "        \"\"\" t is 1-D, u has shape (batch_size, time, dim) \"\"\"\n",
    "        assert t_seq.shape[0] == u_seq.shape[1]\n",
    "        self.t_seq = t_seq.detach().cpu().numpy()\n",
    "        self.u_seq = Variable(u_seq).to(u_seq.device)\n",
    "        self.length = t_seq.shape[0]\n",
    "\n",
    "    def __call__(self, t):\n",
    "        \"\"\" return interpolation of loaded input sequence \"\"\"\n",
    "        idx_right = np.searchsorted(self.t_seq, t.item(), side='left')\n",
    "        idx_left = idx_right - 1\n",
    "\n",
    "        # if extend past sequence, just return last element\n",
    "        if idx_right == self.length:\n",
    "            return self.u_seq[:, -1]\n",
    "\n",
    "        # if hit starting time, return first element\n",
    "        if idx_right == 0:\n",
    "            return self.u_seq[:, 0]\n",
    "\n",
    "        # linear interpolation\n",
    "        t_left = self.t_seq[idx_left]\n",
    "        u_left = self.u_seq[:,idx_left]\n",
    "\n",
    "        u_diff = self.u_seq[:,idx_right] - u_left\n",
    "        t_diff = self.t_seq[idx_right] - t_left\n",
    "        slope = u_diff / t_diff\n",
    "\n",
    "        return slope*(t - t_left) + u_left\n",
    "    \n",
    "\n",
    "class DynamicsWrapper(nn.Module):\n",
    "    \"\"\" nn.Module wrapper to ensure that odeint_adjoint works correctly \"\"\"\n",
    "    def __init__(self, dynamics, input_interpolator):\n",
    "        super().__init__()\n",
    "        self.n = dynamics.n\n",
    "        self.dynamics = dynamics\n",
    "        self.input_interpolator = input_interpolator\n",
    "\n",
    "    def forward(self, t, x):        \n",
    "        return self.dynamics(t, x, self.input_interpolator(t))\n",
    "    \n",
    "\n",
    "class DynamicalSystem(nn.Module):\n",
    "    def __init__(self, dynamics, interpolator):\n",
    "        super().__init__()\n",
    "        self.n = dynamics.n\n",
    "        self.dynamics = dynamics\n",
    "        self.interpolator = interpolator\n",
    "\n",
    "    def forward(self, t, u, x0):\n",
    "        self.dynamics.input_interpolator.init_interpolation(t[0,:], u)\n",
    "        return odeint(self.dynamics, x0, t[0, :], method=\"rk4\", options=dict(step_size=1.0)).permute(1,0,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dynamics = LinearDynamics(n, Tamb=Tamb/scale)\n",
    "interp = LookupLinearInterpolator()\n",
    "wrapped_dynamics = DynamicsWrapper(dynamics, interp)\n",
    "model = DynamicalSystem(wrapped_dynamics, interp)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# downsample and scale data\n",
    "data_interp = {}\n",
    "for i in data.keys():\n",
    "    t, u, T = data[i][\"t\"], data[i][\"u\"], data[i][\"T\"]\n",
    "\n",
    "    t_interp = np.arange(t[0], t[-1], tau)\n",
    "    T_interp = np.interp(t_interp, t, T)\n",
    "    u_interp = np.interp(t_interp, t, u)\n",
    "\n",
    "    data_interp[i] = {\n",
    "        \"t\": t_interp,\n",
    "        \"u\": u_interp,\n",
    "        \"T\": T_interp / scale,\n",
    "    }\n",
    "\n",
    "    print(i, T_interp.shape)\n",
    "\n",
    "# convert data to torch tensor, and scale data\n",
    "def convert(d):\n",
    "    data_torch = {}\n",
    "    for i in d.keys():\n",
    "        data_torch[i] = {\n",
    "            \"t\": torch.tensor(d[i][\"t\"]).reshape(1, -1).float(),\n",
    "            \"u\": torch.tensor(d[i][\"u\"]).reshape(1, -1, 1).float(),\n",
    "            \"T\": torch.tensor(d[i][\"T\"]).reshape(1, -1, 1).float(),\n",
    "        }\n",
    "        data_torch[i][\"x0\"] = data_torch[i][\"T\"][0,0,0].repeat(data_torch[i][\"u\"].shape[0], n)\n",
    "    return data_torch\n",
    "\n",
    "data_torch = convert(data_interp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = []\n",
    "# gradually increase fitting horizon\n",
    "for H in np.arange(10, 1000, 10):\n",
    "    print(\"===== Horizon %d =====\" % H)\n",
    "    for g in optimizer.param_groups:\n",
    "        g['lr'] = 1 / H\n",
    "\n",
    "    # inner loop\n",
    "    for itr in range(1, max(H + 1, 100)):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # fitting loss\n",
    "        loss = 0.0\n",
    "        for i in data_torch.keys():\n",
    "            T_pred = model(data_torch[i][\"t\"][:,:H], data_torch[i][\"u\"][:,:H], data_torch[i][\"x0\"])\n",
    "            loss += (T_pred[0,:,0] - data_torch[i][\"T\"][0,:H,0]).pow(2).mean()\n",
    "\n",
    "        # regularization\n",
    "        loss += l1_reg * model.dynamics.dynamics.A.abs().sum()\n",
    "        loss += l1_reg * model.dynamics.dynamics.B.abs().sum()\n",
    "        # loss += 1e-5 * model.dynamics.dynamics.A.pow(2).sum()\n",
    "        # loss += 1e-5 * model.dynamics.dynamics.B.pow(2).sum()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        losses.append(loss.item())\n",
    "        if itr % 10 == 0:\n",
    "            print(itr, loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.semilogy(losses)\n",
    "A = model.dynamics.dynamics.A.detach().numpy()\n",
    "B = model.dynamics.dynamics.B.detach().numpy() * scale\n",
    "c = model.dynamics.dynamics.c().detach().numpy() * scale\n",
    "\n",
    "print(A)\n",
    "print(B)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in data_torch.keys():\n",
    "    t = data_torch[i][\"t\"].detach().numpy()\n",
    "    T_pred = model(data_torch[i][\"t\"], data_torch[i][\"u\"], data_torch[i][\"x0\"]).detach().numpy()\n",
    "    T_true = data_torch[i][\"T\"].detach().numpy()\n",
    "    plt.plot(t.squeeze(), T_pred[0,:,0], label=\"predicted\")\n",
    "    plt.plot(t.squeeze(), T_true[0,:,0], label=\"true\")\n",
    "    plt.title(\"Power level %d\" % i )\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sanity check\n",
    "def ddt(x, t, u, tu):\n",
    "    ut = np.array([np.interp(t, tu, u)])\n",
    "    return A@x + B @ ut + c\n",
    "\n",
    "for i in data.keys():\n",
    "    t, u, T = data[i][\"t\"], data[i][\"u\"], data[i][\"T\"]\n",
    "    x0 = T[0] * np.ones(n)\n",
    "    x = sp.integrate.odeint(ddt, x0, t, (u, t))\n",
    "\n",
    "    plt.plot(x[:,0], label=\"power level %d, predicted, \" % i)\n",
    "    plt.plot(T, \"--\", label=\"power level %d, true\" % i)\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel(\"time\")\n",
    "plt.ylabel(\"Temp (C)\")\n",
    "plt.savefig(\"temp_model.png\")\n",
    "plt.show()\n",
    "\n",
    "# power level 0\n",
    "x0 = 30. * np.ones(n)\n",
    "x = sp.integrate.odeint(ddt, x0, t, (np.zeros(len(t)), t))\n",
    "plt.plot(x[:,0], label=\"power level %d, predicted, \" % 0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump((A,B,c), open(\"temp_dynamics.p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
